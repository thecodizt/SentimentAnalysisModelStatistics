<p><a target="_blank" href="https://app.eraser.io/workspace/lzNMy7FTtBIm4YmFxroq" id="edit-in-eraser-github-link"><img alt="Edit in Eraser" src="https://firebasestorage.googleapis.com/v0/b/second-petal-295822.appspot.com/o/images%2Fgithub%2FOpen%20in%20Eraser.svg?alt=media&amp;token=968381c8-a7e7-472a-8ed6-4a6626da5501"></a></p>

# A Comparative and Analytical Study of Text Classification Models using Various Metrics and Visualizations
### ABSTRACT
In this paper, we compare the performance of nine machine learning models for text classification on five different datasets of labelled texts. We use various metrics, such as accuracy, precision, recall, and F1-score, to evaluate the models and analyze their strengths and weaknesses. We also visualize the performance records of the models for each dataset using different charts and metrics to facilitate the comparison and identification of the best-performing model. Moreover, we analyze the performance records using different techniques and methods, such as learning curves, confusion matrices, error analysis, feature importance, and sensitivity analysis, to understand the behavior of the models and diagnose any problems or limitations they may have. We find that the best-performing model depends on the characteristics of the dataset, such as the size, the domain, and the class distribution. We also discuss the implications of our findings for choosing the appropriate model for text classification tasks.

### DETAILED DESCRIPTION
![Detailed Description](/.eraser/lzNMy7FTtBIm4YmFxroq___NSX35knPbzTDJN8ATbww765SbPq2___---figure---2Es0-mEUXF5ZQj65QYyAx---figure---h54_7kJ08OF3WOtLWpSwLw.png "Detailed Description")

### KEYWORDS
- text classification
- machine learning
- model comparison
- model analysis
- performance evaluation
- performance visualization
### DATASETS
Dataset

Size

Features

Label Field

Domain

Link

IMDB Movie Reviews Dataset

50,000 reviews

Movie reviews, binary sentiment labels

Binary sentiment labels

Movies

[﻿Link](http://ai.stanford.edu/~amaas/data/sentiment/) 

Sentiment140

1.6 million tweets

Tweet text, polarity labels

Polarity labels

General

[﻿Link](http://help.sentiment140.com/for-students) 

Twitter US Airline Sentiment Dataset

14,640 instances

Tweet text, sentiment labels, negative reasons

Sentiment labels

Airlines

[﻿Link](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) 

UTKML Twitter Spam Detection Competition Dataset

N/A

Tweet text, user information, tweet metadata

Binary spam labels

Spam detection

[﻿Link](https://www.kaggle.com/c/utkmls-twitter-spam-detection-competition) 

Hate Speech and Offensive Language Dataset (DONE)

24,783 tweets

Tweet text, class labels, confidence scores

Class labels (hate speech, offensive language, neither)

Hate speech and offensive language detection

[﻿Link](https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset) 

### MACHINE LEARNING MODELS
- Naive Bayes
- KNN
- SVM
- Logistic Regression
- Decision Tree
- Random Forest
- Gradient Boosting
- XGBoost
- AdaBoost

Here is the literature survey for the papers mentioned in the page:

| Year | Title | Techniques | Features | Performance | Dataset | Limitations |
| ---- | ----- | ---------- | -------- | ----------- | ------- | ----------- |
| 2023 | A deep learning approach using natural language processing and time-series forecasting towards enhanced food safety | NLP, TSF, RL | Product Named Entity Recognition, Product Recall Prediction, Food Safety Risk Analysis | F1-score: 0.94, Recall: 0.93, Precision: 0.95 for PNER; MAE: 0.12, RMSE: 0.16 for PRP; AUC: 0.87 for FSRA | FDA recall announcements, USDA recall announcements, OpenFDA API, Weather API | Limited to US data, requires manual labeling for PNER, relies on surrogate data for PRP |
| 2019 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | LLM, Transformer, Fine-tuning | Bidirectional language representation, Pre-training on large corpus, Fine-tuning on downstream tasks | GLUE score: 80.5%, MultiNLI accuracy: 86.7%, SQuAD v1.1 F1: 93.2%, SQuAD v2.0 F1: 83.1% | BooksCorpus, Wikipedia, GLUE, MultiNLI, SQuAD | Requires large amount of compute resources, suffers from pretrain-finetune discrepancy, vulnerable to adversarial attacks |
| 2022 | Text Classification for Predicting Multi-level Product Categories | LLM, Text Classification, SVM, XGBoost | Product title classification, Dynamic masking of subcategories, Bilingual product titles | Accuracy: 0.92 for SVM, 0.93 for XGBoost, 0.96 for BERT-base, 0.97 for BERT-large | Getir dataset (Turkish and English product titles) | Limited to grocery products, requires fine-tuning for each level of categorization, does not consider product descriptions or images |

Here are the six points under software engineering design from the current web page context in a 3x2 table format:

| Mobile Frontend Architecture | Backend Architecture |
| :--------------------------: | :------------------: |
| Cross-platform framework (React Native or Flutter) | Scalable technology (Node.js or Django) |
| QR code scanning library (react-native-camera) | Processing of data received from QR codes |²[2]

| Database Architecture | Microservices Architecture |
| :-------------------: | :-----------------------: |
| RDBMS (PostgreSQL or MySQL) for structured data | Each module (sales analytics, forecasting, etc.) as a separate microservice |
| NoSQL database (MongoDB or Couchbase) for unstructured data | Scalability and maintainability |³[3]

| Cloud Deployment | Security Measures |
| :--------------: | :--------------: |
| AWS or Google Cloud Platform using Docker and Kubernetes | Encryption, HTTPS, security audits, GDPR compliance |



<!--- Eraser file: https://app.eraser.io/workspace/lzNMy7FTtBIm4YmFxroq --->
